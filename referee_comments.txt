##################
Referee A Comments
##################

1. It is claimed in a number of places in the text that the
computational cost of searches for compact object mergers is tied to
improvements in the low-frequency sensitivity of gravitational-wave
detectors. For example, in the abstract there is the statement

"However, the computational cost of such searches in low latency will
grow dramatically as the low frequency sensitivity of
gravitational-wave detectors improves."

and in the second paragraph of the Introduction

"The computational cost to run the search analysis is due to the large
parameter space and the increasing cost of analyzing longer duration
waveforms as the low frequency sensitivity of the detectors improves."

These claims are not true. They would be true for a naive,
brute-force, template bank + matched-filter approach, as was used in
the early days of LIGO, but they are not true for modern detection
systems. The low frequency parts of the signals have two properties
relevant here: firstly, they're low frequency meaning the filtering of
these parts of the waveforms can be computed at a lower sample rate;
secondly the rate of frequency evolution at low frequencies is small
due to the slow rate of energy loss from the system, making the
structure of the waveforms more and more simple at low frequencies.
Modern detection systems, for example the Multi-Band Template Analysis
(MBTA) and GstLAL-based detection systems, take advantage of both of
these properties to remove redundancy from the calculations and reduce
the computational cost. The result is that the cost is nearly
independent of the starting frequency; the computational cost is
entirely dominated by the high frequency parts of the waveform where
high data sample rates are required and complex frequency and
amplitude evolution are observed.

I cannot find anywhere in this document an accounting of the
computational cost of the convolutional neural network nor of the
matched filtering approach, and I feel that without that information a
discussion of the computational cost of either of the approaches, or
in particular their scalings, is out of place. I will raise this issue
again below, but I think perhaps removing any sort of claims of speed,
cost, whatever, is warranted, unless a comparative study is presented
to support them.

1)* --- If we decide to keep in the bit where we describe the source of computational cost in a matched filtering analysis, then we should also say that the majority of the expense comes from the high frequency portion of the waveform. What are folks thoughts about keeping these statements in? I'm of the opinion that it is important given that the advantage of using a neural network is that it can run faster than a matched template filtering analysis.


2. Introduction, second paragraph, "... in these search pipelines is
achieved using a technique known as ..." --> ... in these search
pipelines is achieved, in part, using a technique known as ..." In
fact the process also makes of use various \chi^2-like statistics, and
various measures of signal consistency across the multiple detectors
world-wide.

2)* --- Shouldn't be difficult to mention chi^2 here.

3. Introduction, third paragraph, "... each with different component
mass components and/or ..." --> "... each with different component
mass and/or ..."


4. Introduction, fourth paragraph, the claim "This results in
low-latency searches that can be orders of magnitude faster than other
comparable classification methods." requires a reference. There are
weasel words in there, "can be", "comparable" (what are "comparable"
methods? only the ones for which this statement is true?), and because
of that strictly speaking no specific claim is being made here, but a
claim is being implied and I am certain that claim is false. I am
reminded of similar claims made about GPU-based FFT algorithms: orders
of magnitude faster, 100x faster, and so on. It is true that the GPU
can perform a subset of the tasks required to identify
gravitational-wave signals at an enormously higher speed than a CPU,
but it can't do all of the tasks at that speed. If 50% of the tasks
can be done so quickly that they are reduced to 0 time, you have only
increased the speed by a factor of 2, not 100s or 1000s, because there
remains the other 50% of the tasks that still take just as long.
Meanwhile, if you merely wait 18 months Moore's Law will give you that
factor of 2, anyway, without having to spend time porting your
algorithm to GPUs. This is the Achilles' heal of GPUs: they're a lot
of work, and there are things they're not good at, which is why the
use of GPUs for matched filtering based GW detection systems has never
gained traction. Anyway, if a reference to support this claim cannot
be found it should be removed.


5. I am also puzzled by the claim that has been made in the abstract
and again here that "the majority of calculations are performed prior
to data taking during a training process." The fact that there is a
set-up phase that requires more calculations than are required to
analyze the data does not imply a reduction in computational cost, as
I feel the authors intend. It implies an enormous explosion in
computational cost: not only is there still the cost to analyze the
data, but now on top of that there is a huge start-up cost as well.
Again, I don't find a comparison of computational cost presented in
this manuscript. If the work presented here is a net reduction in
computational cost compared to normal matched filtering, then this
should be quantified somehow. By the way, as I mentioned above, modern
detection systems do not make use of matched filtering implemented in
the "convolve data with all waveforms at full sample rate" form,
however the ratio of the cost of doing that to the true cost of modern
systems is well documented elsewhere, so it's not necessary to compare
your system to real-world, as-implemented, filtering costs. It's
sufficient to compare the cost of your system to the full
matched-filtering approach, as that forms a common benchmark for
comparison.

An alternative is to simply not discuss the computational cost; remove
claims or suggestions of an improvement with respect to something
else. I think the technical achievement of demonstrating the
suitability of convolutional neural networks for GW signal detection
is sufficient to warrant publication. For example, some neural
networks can be efficiently implemented on FPGAs, which are not
necessarily suitable for traditional matched-filtering. Even if the
approach described here is more computationally costly than modern
matched-filtering on a traditional CPU, it's possible that there are
avenues available for hardware optimization that are not available to
matched-filtering. Therefore, how practical or not this approach is is
potentially a complex problem, and exploring that is likely beyond the
scope of this work.

If the authors have data on the relative performance of their system,
then by all means I encourage them to add that to this manuscript. I
merely mean to say that if they do not, then I would not require them
to spend the time obtaining it to proceed with publication. But in
that case they must remove claims regarding the performance of the
system.


6. Page 2, second paragraph, "They typically then merge on the
timescale of O(1) sec ..." --> "They typically then merge on the
timescale of O(1 s) ...". Two violations of SI style conventions:
separating a number from its unit, and using a non-standard
abbreviation (https://physics.nist.gov/cuu/Units/rules.html).



7. Equation (1) needs a reference. Otherwise you need define
normalization conventions for, e.g., Sn(f), and Fourier transforms.


8. Below equation (1), I'm puzzled by the extremely short interval of
data that has been used. 1 s is much less than the impulse length of
the filter required to whiten Advanced LIGO data (typically 10 s or
longer in length). Attempting to whiten so short a piece of data will
lead to undesirable, non-physical, boundary artifacts. This deserves
some explanation: how have they whitened it? Did they start with a
much larger piece, first, and extract the 1 s after? By what measure
is the result considered acceptable for the purposes of this analysis?
I realize there is a description of padding the data by 1/2 s on each
side, but that is still an order of magnitude too small under normal
circumstances. It's possible that because Gaussian noise is being used
the spectrum is sufficiently smooth, i.e., it lacks the narrow
spectral features of real data, for whitening so short an interval to
not be a problem. But, still, that should be explained because it
stands out as a surprising configuration choice.


9. Throughout this section, SI units are not being used correctly. "1
sec" --> "1 s", or "one second".
https://physics.nist.gov/cuu/Units/checklist.html



10. Equations (3) and (4) need references.


11. One of the things that I notice in Fig 2. is that the CNN does not
appear to offer any sensitivity improvement at higher or very low
SNRs, but it appears to offer one in the marginal SNR regime, e.g.,
SNR=4. By chance this corresponds to the SNR at which matched-filter +
trigger systems give up. For example the GstLAL detection system
operates at a trigger threshold of 4. Because of the very high
false-alarm rate, and the data management burden that creates, it is
not practical to collect triggers at a lower SNR threshold. It is
known, however, that doing so would improve the sensitivity of the
search. If a system was a available for producing triggers in the
range, say, 3 <= SNR <= 4 and this system had a lower false-alarm rate
than matched filtering in that regime, then that would allow detection
systems to operate at a lower threshold. It's possible some sort of
hybrid system would be best, where a CNN is responsible for
identifying the very low SNR triggers and a traditional
matched-filtering system is used for higher SNR things. I don't have
any specific comment or request to make in this regard, only that if
the issue of the performance at higher and lower SNRs is raised, then
pointing out the utility in the marginal SNR regime, would be apropos.



##################
Referee B Comments
##################


* Does the method scale up to searches over the full gravitational
waveform parameter space, including the parts that would be covered
(in a matched-filter search) by very closely spaced and very long
waveforms? (The test case used this part of parameter space that is in
the opposite extreme, namely short and well spaced signals.)


* Can the authors make any kind of quantitative statement about the
comparison in computational costs between the neural network method
and the matched filter technique? And if so, does that scale in a
benign way as the neural network is expanded to the full parameter
space?



